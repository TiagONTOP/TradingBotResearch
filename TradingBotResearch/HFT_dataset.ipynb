{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8523f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import MetaTrader5 as mt\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from math import ceil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f67a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mettre les identifiants FTMO MetaTrader5\n",
    "mt.initialize()\n",
    "\n",
    "login_mt5 = 1051534030\n",
    "mdp_mt5 = 'FG2SF2M74R'\n",
    "server = 'FTMO-Demo'\n",
    "\n",
    "mt.login(login_mt5, mdp_mt5, server)\n",
    "type(mt.positions_total())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd9a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AUDCAD', 'AUDJPY', 'AUDNZD', 'AUDCHF', 'AUDUSD', 'GBPAUD', \n",
    "           'GBPCAD', 'GBPJPY', 'GBPNZD', 'GBPCHF', 'GBPUSD', 'CADJPY',\n",
    "           'CADCHF', 'EURAUD', 'EURGBP', 'EURCAD', 'EURJPY', 'EURCHF', \n",
    "           'EURUSD', 'EURNZD', 'NZDCAD', 'NZDCHF', 'NZDUSD', 'NZDJPY',\n",
    "           'CHFJPY', 'USDCAD', 'USDCHF', 'USDJPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92eb9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_mt5_data(tickers, interval):\n",
    "    \n",
    "    datas = []\n",
    "    for ticker in tickers:\n",
    "        \n",
    "        data = pd.DataFrame(mt.copy_rates_from(ticker, interval, datetime.now(), 99999))\n",
    "        data['time'] = pd.to_datetime(data['time'], unit='s')\n",
    "        data['symbol'] = np.full(shape=len(data), fill_value=ticker)\n",
    "        data = data.drop(['real_volume'], axis=1)\n",
    "        datas.append(data)\n",
    "    \n",
    "    data = pd.concat(datas, axis=0)\n",
    "    data = data.set_index(['symbol', 'time'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad28463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_data(data, \n",
    "                      momentums=True, \n",
    "                      ema_spread=True, \n",
    "                      ema_accel=True,\n",
    "                      rsi=True,\n",
    "                      rsi_lag=True,\n",
    "                      rsi_longrun=True,\n",
    "                      rsi_longrun_lag=True,\n",
    "                      log_returns_lag=True,\n",
    "                      rolling_std=True,\n",
    "                      parkinson=True,\n",
    "                      parkinson_lag=True,\n",
    "                      tick_volume_lag=True,\n",
    "                      spread_lag=True,\n",
    "                      tickers_token=True,\n",
    "                      frac_diff=False,\n",
    "                      windows=None,\n",
    "                      target_window=[1]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates various technical analysis features from the input data and adds them to the input data DataFrame.\n",
    "\n",
    "    Args:\n",
    "    data (DataFrame): Input data containing OHLCV columns\n",
    "    momentums (bool): Whether or not to calculate momentum features (default True)\n",
    "    ema_spread (bool): Whether or not to calculate EMA spread features (default True)\n",
    "    ema_accel (bool): Whether or not to calculate EMA acceleration features (default True)\n",
    "    rsi (bool): Whether or not to calculate RSI features (default True)\n",
    "    rsi_lag (bool): Whether or not to calculate lagged RSI features (default True)\n",
    "    rsi_longrun (bool): Whether or not to calculate long-run RSI features (default True)\n",
    "    rsi_longrun_lag (bool): Whether or not to calculate lagged long-run RSI features (default True)\n",
    "    log_returns_lag (bool): Whether or not to calculate log-returns lag features (default True)\n",
    "    rolling_std (bool): Whether or not to calculate rolling standard deviation features (default True)\n",
    "    parkinson (bool): Whether or not to calculate Parkinson volatility features (default True)\n",
    "    parkinson_lag (bool): Whether or not to calculate lagged Parkinson volatility features (default True)\n",
    "    tick_volume_lag (bool): Whether or not to calculate lagged tick volume features (default True)\n",
    "    spread_lag (bool): Whether or not to calculate lagged spread features (default True)\n",
    "    tickers_token (bool): Whether or not to tokenize the tickers features (default True)\n",
    "    frac_diff (bool): Whether or not to calculate fractional differentiation features (default False)\n",
    "    windows (dict): A dictionary containing windows values for each feature\n",
    "    target_window (int): The target window for prediction (default 1)\n",
    "\n",
    "    Returns: cleaned data\n",
    "    \n",
    "    \n",
    "    Example of use with a \"windows\" window dictionary:\n",
    "    \n",
    "    windows_example = {\n",
    "        'momentum_windows': [10, 20, 30, 50],\n",
    "        'ema_window': 14,\n",
    "        'ema_accel_windows': [1, 5, 10, 30],\n",
    "        'rsi_lags': [1, 5, 10, 20, 50],\n",
    "        'rsi_longrun_lag': [20, 50, 100, 200, 300],\n",
    "        'parkinson_lag': [10, 20, 30],\n",
    "        'tick_volume_lag': [1, 5, 10, 20],\n",
    "        'spread_lag': [5, 10, 20]\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if windows is None:\n",
    "        windows = {}\n",
    "    #Calcul du momentum\n",
    "    if momentums:\n",
    "        if windows.get('momentum_windows') is None:\n",
    "            momentum_windows = [30, 60, 120, 240, 480, 1060]\n",
    "        else:\n",
    "            momentum_windows = windows['momentum_windows']\n",
    "        \n",
    "        for lag in momentum_windows:\n",
    "            data[f'momentum_{lag}p'] = data.groupby(level='symbol', group_keys=False).apply(lambda x: x.close.pct_change(lag))\n",
    "    \n",
    "    #Calcul du spread ema\n",
    "    if ema_spread:\n",
    "        if windows.get('ema_window') is None:\n",
    "            ema_window = 20\n",
    "        else:\n",
    "            ema_window = windows['ema_window']\n",
    "        ema = (data\n",
    "               .groupby(level='symbol', group_keys=False)\n",
    "               .apply(lambda x: ta.EMA(x.close, timeperiod=ema_window)))\n",
    "        data[f'ema_spread{ema_window}'] = data.close - ema\n",
    "    #Calcul de l'acceleration ema\n",
    "    \n",
    "        if ema_accel:\n",
    "            if windows.get('ema_accel_windows') is None:\n",
    "                ema_accel_windows = [1, 5, 10, 30]\n",
    "\n",
    "            else:\n",
    "                ema_accel_windows = windows['ema_accel_windows']\n",
    "        for lag in ema_accel_windows:\n",
    "            data[f'ema_accel_{lag}p'] = ema.groupby(level='symbol', group_keys=False).apply(lambda x: x.pct_change(lag))\n",
    "        \n",
    "    #Calcul de l'RSI classique 14p et d'un autre plus long terme\n",
    "    \n",
    "    if rsi:\n",
    "        data['rsi'] = data.groupby(level='symbol', group_keys=False).apply(lambda x: ta.RSI(x.close))\n",
    "        \n",
    "        if rsi_lag:\n",
    "            if windows.get('rsi_lags') is None:\n",
    "                rsi_lags = [1, 5, 10, 20, 25, 35, 50]\n",
    "\n",
    "            else:\n",
    "                rsi_lags = windows['rsi_lags']\n",
    "                \n",
    "            for lag in rsi_lags:\n",
    "                \n",
    "                data[f'rsi_lag_{lag}'] = data.groupby(level='symbol', group_keys=False).apply(lambda x: x.rsi.shift(lag))\n",
    "                \n",
    "    if rsi_longrun:\n",
    "        \n",
    "        data['rsi_longrun'] = data.groupby(level='symbol', group_keys=False).apply(lambda x: ta.RSI(x.close, timeperiod=100))\n",
    "        \n",
    "        if rsi_longrun_lag:\n",
    "            if windows.get('rsi_longrun_lag') is None:\n",
    "                rsi_longrun_lag = [10, 20, 30, 50, 100, 150, 200]\n",
    "\n",
    "            else:\n",
    "                rsi_longrun_lag = windows['rsi_longrun_lag']\n",
    "                \n",
    "            for lag in rsi_longrun_lag:\n",
    "                \n",
    "                data[f'rsi_lr_lag_{lag}'] = data.groupby(level='symbol', group_keys=False).apply(lambda x: x.rsi.shift(lag))\n",
    "                \n",
    "    # Calcul des log-rentabilités\n",
    "    if log_returns_lag:\n",
    "        \n",
    "        if windows.get('log_returns_lags') is None:\n",
    "            \n",
    "            log_returns_lags = list(range(1, 10))\n",
    "        \n",
    "        else:\n",
    "            log_returns_lags = windows['log_returns_lags']\n",
    "            \n",
    "        data['log_returns_lag_0p'] = (data\n",
    "                                      .groupby(level='symbol', group_keys=False)\n",
    "                                      .apply(lambda x: np.log(x.close/x.close.shift(1))))\n",
    "        for lag in log_returns_lags:\n",
    "            data[f'log_returns_lag_{lag}p'] = (data\n",
    "                                               .groupby(level='symbol', group_keys=False)\n",
    "                                               .apply(lambda x: x.log_returns_lag_0p.shift(lag)))\n",
    "    # Calcul de l'écart-type mobile    \n",
    "    if rolling_std:\n",
    "        \n",
    "        if windows.get('windows_std') is None:\n",
    "            \n",
    "            windows_std = [20, 50, 150, 300]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            windows_std = windows['windows_std']\n",
    "        \n",
    "        for window_std in windows_std:\n",
    "            \n",
    "            data[f'rolling_std_{window_std}w'] = (data\n",
    "                                                  .groupby(level='symbol', group_keys=False, as_index=False)['log_returns_lag_0p']\n",
    "                                                  .rolling(window_std)\n",
    "                                                  .std()\n",
    "                                                  .drop(['symbol'], axis=1))\n",
    "    # Calcul de la volatilité de parkinson\n",
    "    \n",
    "    if parkinson:\n",
    "        \n",
    "        data['parkinson'] = (data\n",
    "                             .groupby(level='symbol', group_keys=False)\n",
    "                             .apply(lambda x: np.sqrt((1/4*np.log(2)) * np.log(x.high/x.low)**2)))\n",
    "        \n",
    "        if parkinson_lag:\n",
    "            if windows.get('parkinson_lags') is None:\n",
    "                \n",
    "                parkinson_lags = list(range(1, 10))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                parkinson_lags = windows['parkinson_lags']\n",
    "                \n",
    "            for lag in parkinson_lags:\n",
    "                \n",
    "                data[f'parkinson_{lag}p'] = (data\n",
    "                                             .groupby(level='symbol', group_keys=False)\n",
    "                                             .apply(lambda x: x.parkinson.shift(lag)))\n",
    "    \n",
    "    # Mise en retard du volume\n",
    "    if tick_volume_lag:\n",
    "        \n",
    "        if windows.get('tick_volume_lags') is None:\n",
    "            \n",
    "            tick_volume_lags = list(range(1, 10))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            tick_volume_lags = windows['tick_volume_lags']\n",
    "            \n",
    "        for lag in tick_volume_lags:\n",
    "            \n",
    "            data[f'tick_volume_{lag}p'] = (data\n",
    "                                           .groupby(level='symbol', group_keys=False)\n",
    "                                           .apply(lambda x: x.tick_volume.shift(lag)))\n",
    "    # Mise en retard du spread       \n",
    "    if spread_lag:\n",
    "        \n",
    "        if windows.get('spread_lags') is None:\n",
    "            \n",
    "            spread_lags = list(range(1, 10))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            spread_lags = windows['spread_lags']\n",
    "            \n",
    "        for lag in spread_lags:\n",
    "            \n",
    "            data[f'spread_lags_{lag}p'] = (data.groupby(level='symbol', group_keys=False)\n",
    "                                           .apply(lambda x: x.spread.shift(lag)))\n",
    "            \n",
    "    # Tokenization des tickers        \n",
    "    if tickers_token:\n",
    "        \n",
    "        data['ticker_token'] = pd.factorize(data.index.get_level_values(0))[0]\n",
    "    \n",
    "    # frac diff pas encore disponible\n",
    "    if frac_diff:\n",
    "        pass    \n",
    "    \n",
    "    #nétoyage et préparation des données finales\n",
    "    for lag in target_window:\n",
    "        data[f'target_{lag}p'] = (data.groupby(level='symbol', group_keys=False)\n",
    "                                            .apply(lambda x: np.log(x.close/x.close.shift(lag))))\n",
    "        data[f'target_{lag}p'] = data[f'target_{lag}p'].shift(-lag)\n",
    "    prices = data[['open', 'high', 'low', 'close', 'tick_volume', 'spread']]\n",
    "    data = data.drop(['open', 'high', 'low', 'close'], axis=1)\n",
    "    data = data.dropna(how='any')\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.fillna(method='ffill')\n",
    "    \n",
    "    return data, prices\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8494b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VAR_logic_data(data, momentum=True, lags=list(range(1, 11))):\n",
    "    \n",
    "    windows={\n",
    "        'momentum_windows' : [30, 60, 120, 240, 480, 960, 2000],\n",
    "        'log_returns_lags' : lags\n",
    "        \n",
    "    }\n",
    "    \n",
    "    data, prices = get_features_data(data, \n",
    "                      momentums=momentum, \n",
    "                      ema_spread=False, \n",
    "                      ema_accel=False,\n",
    "                      rsi=False,\n",
    "                      rsi_lag=False,\n",
    "                      rsi_longrun=False,\n",
    "                      rsi_longrun_lag=False,\n",
    "                      log_returns_lag=True,\n",
    "                      rolling_std=False,\n",
    "                      parkinson=False,\n",
    "                      parkinson_lag=False,\n",
    "                      tick_volume_lag=False,\n",
    "                      spread_lag=False,\n",
    "                      tickers_token=False,\n",
    "                      frac_diff=False,\n",
    "                      windows=windows,\n",
    "                      target_window=[1])\n",
    "    data = data.drop(['tick_volume', 'spread'], axis=1)\n",
    "    target_name = [target for target in data.columns if 'target' in target][0]\n",
    "    target = data.pop(target_name)\n",
    "    columns_wewant = data.columns\n",
    "    for ticker in data.index.levels[0]:\n",
    "        join = data.loc[ticker][columns_wewant]\n",
    "        join.columns = [f'{c}_{ticker}' for c in join.columns]\n",
    "        data = data.join(join, on='time')\n",
    "    \n",
    "    data = data.join(target)\n",
    "    data = data.drop(columns_wewant, axis=1)\n",
    "    data = data.fillna(method='ffill')\n",
    "    data = data.dropna()\n",
    "    return data, prices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d8f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_clean_mt5_data(symbols, mt.TIMEFRAME_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c37394a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data, prices \u001b[38;5;241m=\u001b[39m \u001b[43mget_VAR_logic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 9\u001b[0m, in \u001b[0;36mget_VAR_logic_data\u001b[1;34m(data, momentum, lags)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_VAR_logic_data\u001b[39m(data, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m))):\n\u001b[0;32m      3\u001b[0m     windows\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_windows\u001b[39m\u001b[38;5;124m'\u001b[39m : [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m240\u001b[39m, \u001b[38;5;241m480\u001b[39m, \u001b[38;5;241m960\u001b[39m, \u001b[38;5;241m2000\u001b[39m],\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_returns_lags\u001b[39m\u001b[38;5;124m'\u001b[39m : lags\n\u001b[0;32m      6\u001b[0m         \n\u001b[0;32m      7\u001b[0m     }\n\u001b[1;32m----> 9\u001b[0m     data, prices \u001b[38;5;241m=\u001b[39m \u001b[43mget_features_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmomentums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mema_spread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mema_accel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mrsi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mrsi_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mrsi_longrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mrsi_longrun_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mlog_returns_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mrolling_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mparkinson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mparkinson_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtick_volume_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mspread_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtickers_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfrac_diff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mwindows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtarget_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtick_volume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspread\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m     target_name \u001b[38;5;241m=\u001b[39m [target \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m target][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[52], line 72\u001b[0m, in \u001b[0;36mget_features_data\u001b[1;34m(data, momentums, ema_spread, ema_accel, rsi, rsi_lag, rsi_longrun, rsi_longrun_lag, log_returns_lag, rolling_std, parkinson, parkinson_lag, tick_volume_lag, spread_lag, tickers_token, frac_diff, windows, target_window)\u001b[0m\n\u001b[0;32m     69\u001b[0m         momentum_windows \u001b[38;5;241m=\u001b[39m windows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_windows\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m momentum_windows:\n\u001b[1;32m---> 72\u001b[0m         data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mclose\u001b[38;5;241m.\u001b[39mpct_change(lag))\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#Calcul du spread ema\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ema_spread:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4165\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4167\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4180\u001b[0m     ):\n\u001b[0;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4911\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_dict_like(value):\n\u001b[1;32m-> 4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   4915\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:12020\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12018\u001b[0m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[0;32m  12019\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 12020\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  12021\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12022\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12024\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:5094\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5090\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5091\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m passed as both positional and keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5092\u001b[0m         )\n\u001b[0;32m   5093\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index})\n\u001b[1;32m-> 5094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5288\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5290\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5304\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5301\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5303\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5304\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5308\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5309\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5310\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5311\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5312\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5313\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5314\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4412\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 4412\u001b[0m         indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4413\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\n\u001b[0;32m   4414\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4415\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[0;32m   4416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3973\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_get_indexer(\n\u001b[0;32m   3970\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   3971\u001b[0m     )\n\u001b[1;32m-> 3973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3994\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3991\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   3992\u001b[0m     \u001b[38;5;66;03m# error: Item \"IndexEngine\" of \"Union[IndexEngine, ExtensionEngine]\"\u001b[39;00m\n\u001b[0;32m   3993\u001b[0m     \u001b[38;5;66;03m# has no attribute \"_extract_level_codes\"\u001b[39;00m\n\u001b[1;32m-> 3994\u001b[0m     tgt_values \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_level_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[union-attr]\u001b[39;49;00m\n\u001b[0;32m   3995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3998\u001b[0m     tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:662\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine._extract_level_codes\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6052\u001b[0m, in \u001b[0;36mIndex.get_indexer_for\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m   6034\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6035\u001b[0m \u001b[38;5;124;03mGuaranteed return of an indexer even when non-unique.\u001b[39;00m\n\u001b[0;32m   6036\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6049\u001b[0m \u001b[38;5;124;03marray([0, 2])\u001b[39;00m\n\u001b[0;32m   6050\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 6052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6053\u001b[0m indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m   6054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3973\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m this\u001b[38;5;241m.\u001b[39m_get_indexer(\n\u001b[0;32m   3970\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   3971\u001b[0m     )\n\u001b[1;32m-> 3973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4000\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3997\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3998\u001b[0m         tgt_values \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39m_get_engine_target()\n\u001b[1;32m-> 4000\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, prices = get_VAR_logic_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f88f7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore('data.h5') as hdf:\n",
    "    hdf.put('data_rsi_filtre2', data)\n",
    "    hdf.put('prices_rsi_filtre2', prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819ac3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005003452301025391\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(100000):\n",
    "    x = 1+1\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750092f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, prices = get_features_data(data, spread_lag=False, tick_volume_lag=False, \n",
    "                                 parkinson_lag=False, rsi_lag=False, rsi_longrun=False,\n",
    "                                 rsi_longrun_lag=False, windows={'windows_std' : [50],\n",
    "                                                                 'momentum_windows': [30, 60, 120, 240, 480, 1060, 2120, 3180]}, \n",
    "                                 target_window=[1, 5, 10, 30, 60, 120, 240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0466117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_hdf('data.h5', 'HFT_M1_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef9a4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 4056279 entries, ('AUDCAD', Timestamp('2022-12-29 15:01:00')) to ('USDTRY', Timestamp('2023-04-06 09:38:00'))\n",
      "Data columns (total 73 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   tick_volume         uint64 \n",
      " 1   spread              int32  \n",
      " 2   momentum_30p        float64\n",
      " 3   momentum_60p        float64\n",
      " 4   momentum_120p       float64\n",
      " 5   momentum_240p       float64\n",
      " 6   momentum_480p       float64\n",
      " 7   momentum_1060p      float64\n",
      " 8   ema_spread20        float64\n",
      " 9   ema_accel_1p        float64\n",
      " 10  ema_accel_5p        float64\n",
      " 11  ema_accel_10p       float64\n",
      " 12  ema_accel_30p       float64\n",
      " 13  rsi                 float64\n",
      " 14  rsi_lag_1           float64\n",
      " 15  rsi_lag_5           float64\n",
      " 16  rsi_lag_10          float64\n",
      " 17  rsi_lag_20          float64\n",
      " 18  rsi_lag_25          float64\n",
      " 19  rsi_lag_35          float64\n",
      " 20  rsi_lag_50          float64\n",
      " 21  rsi_longrun         float64\n",
      " 22  rsi_lr_lag_10       float64\n",
      " 23  rsi_lr_lag_20       float64\n",
      " 24  rsi_lr_lag_30       float64\n",
      " 25  rsi_lr_lag_50       float64\n",
      " 26  rsi_lr_lag_100      float64\n",
      " 27  rsi_lr_lag_150      float64\n",
      " 28  rsi_lr_lag_200      float64\n",
      " 29  log_returns_lag_0p  float64\n",
      " 30  log_returns_lag_1p  float64\n",
      " 31  log_returns_lag_2p  float64\n",
      " 32  log_returns_lag_3p  float64\n",
      " 33  log_returns_lag_4p  float64\n",
      " 34  log_returns_lag_5p  float64\n",
      " 35  log_returns_lag_6p  float64\n",
      " 36  log_returns_lag_7p  float64\n",
      " 37  log_returns_lag_8p  float64\n",
      " 38  log_returns_lag_9p  float64\n",
      " 39  rolling_std_20w     float64\n",
      " 40  rolling_std_50w     float64\n",
      " 41  rolling_std_150w    float64\n",
      " 42  rolling_std_300w    float64\n",
      " 43  parkinson           float64\n",
      " 44  parkinson_1p        float64\n",
      " 45  parkinson_2p        float64\n",
      " 46  parkinson_3p        float64\n",
      " 47  parkinson_4p        float64\n",
      " 48  parkinson_5p        float64\n",
      " 49  parkinson_6p        float64\n",
      " 50  parkinson_7p        float64\n",
      " 51  parkinson_8p        float64\n",
      " 52  parkinson_9p        float64\n",
      " 53  tick_volume_1p      float64\n",
      " 54  tick_volume_2p      float64\n",
      " 55  tick_volume_3p      float64\n",
      " 56  tick_volume_4p      float64\n",
      " 57  tick_volume_5p      float64\n",
      " 58  tick_volume_6p      float64\n",
      " 59  tick_volume_7p      float64\n",
      " 60  tick_volume_8p      float64\n",
      " 61  tick_volume_9p      float64\n",
      " 62  spread_lags_1p      float64\n",
      " 63  spread_lags_2p      float64\n",
      " 64  spread_lags_3p      float64\n",
      " 65  spread_lags_4p      float64\n",
      " 66  spread_lags_5p      float64\n",
      " 67  spread_lags_6p      float64\n",
      " 68  spread_lags_7p      float64\n",
      " 69  spread_lags_8p      float64\n",
      " 70  spread_lags_9p      float64\n",
      " 71  ticker_token        int64  \n",
      " 72  target_1p           float64\n",
      "dtypes: float64(70), int32(1), int64(1), uint64(1)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
